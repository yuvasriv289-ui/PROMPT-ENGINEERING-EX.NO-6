# Ex.No.6 Development of Python Code Compatible with Multiple AI Tools

# Date:25/12/2025
# Register no:25008890
# Aim: Write and implement Python code that integrates with multiple AI tools to automate the task of interacting with APIs, comparing outputs, and generating actionable insights with Multiple AI Tools

#AI Tools Required:
ChatGPT (OpenAI)

Gemini (Google)

Claude (Anthropic)

Copilot (Microsoft)

Exercise Description:

Students will practice creating prompts to guide AI tools for the following tasks:

Generate Python code for interacting with multiple APIs.

Compare outputs from different APIs and highlight differences.

# Explanation:

Apply the persona pattern by specifying the role of the AI as a programmer.

Focus on applications related to your area of interest.

Use multiple AI tools to generate code for the same task.

Analyze and discuss the outputs from different tools.

Sample Prompts Designed:

Python Code Generation Prompt: "As a Python developer, generate code that fetches weather data from both OpenWeatherMap and WeatherAPI, stores results in a structured format, and handles errors gracefully."

Comparison Prompt: "Compare the outputs from OpenWeatherMap API and WeatherAPI for the same city, highlight differences in temperature, humidity, and weather description, and summarize in a table."

Insight Generation Prompt: "Based on the API comparison results, provide actionable insights for a dashboard that displays weather metrics accurately for different cities."

AI-Generated Responses:

ChatGPT: Provided Python code with API calls, JSON handling, comparison logic, and a summary table. Clear comments included.

Gemini: Generated code with alternative libraries for HTTP requests, handling API keys securely, and a summary function.

Claude: Focused on structured output and highlighted differences with descriptive messages.

Copilot: Suggested modular code templates and reusable functions for API integration and comparison.

Analysis & Discussion:

Effectiveness of Prompts: Clear and role-specific prompts led to well-structured, working code across all tools.

Comparing Outputs: Different AI tools suggested slightly different approaches but all achieved the main objectives.

Insights: Persona pattern helps AI understand the coding context and produce actionable and usable code.

Next Steps:

Refine prompts to handle edge cases.

Integrate multiple API outputs into a real-time dashboard.

Extend prompts for additional metrics and visualization.

#Conclusion:

The prompts were executed successfully, generating Python code for API integration, comparison, and insights. The exercise demonstrated that structured, role-specific prompts improve the quality and usability of AI-generated code. Using multiple AI tools provides alternative approaches and insights for coding tasks.

#Result:

The designed prompts guided AI tools effectively to produce functional Python code and actionable analysis. The approach validated the importance of prompt design and persona pattern application in AI-assisted project coding.

Deliverable:

Designed prompts for each stage.

AI-generated code and explanations.

Reflection on prompt effectiveness and possible refinements.

#Result: 
The corresponding Prompt is executed successfully.
